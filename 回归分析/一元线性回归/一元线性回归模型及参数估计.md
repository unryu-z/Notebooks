## 一元线性模型的数学形式

一元线性回归**模型式**：

$y = {\beta _0} + {\beta _1}x + \varepsilon$

其中，${\beta _0}$为回归常数，${\beta _1}$为回归系数，$\varepsilon$为其它随机因素的影响

## 基本假设

### 一般假设

一般假设$\varepsilon$是不可观测的随机误差，它是一个随机变量，通常假定$\varepsilon$满足：

$\left\{ \begin{array}{l}
E(\varepsilon ) = 0\\
Var(\varepsilon ) = {\sigma ^2}
\end{array} \right.$

对模型式两端求条件期望，可得：

$E(y\left| x \right.) = {\beta _0} + {\beta _1}x$

如果获得了$n$个样本观测值$({x_1},{y_1}),({x_2},{y_2}), \cdots ,({x_n},{y_n})$符合模型，且这$n$组数据是**独立观测**的，因此$y _1,y_2,\cdots,y_n$和${ \varepsilon _1},\varepsilon_2,\cdots,\varepsilon_n$都是相互对立的随机变量，则

$y _i= {\beta _0} + {\beta _1} x _i + \varepsilon _i$

因此有

$\left\{ \begin{array}{l}
E(y _i) = {\beta _0} + {\beta _1} x _i\\
Var(y _i ) = {\sigma ^2}
\end{array} \right.$

由此可知，$y _1,y_2,\cdots,y_n$是**独立不同分布**的随机变量

### 正态假设

假定模型式中误差项$\varepsilon$服从**正态分布**，即：

${\varepsilon}  \sim N(0,{\sigma ^2})$

由于${ \varepsilon _1},\varepsilon_2,\cdots,\varepsilon_n$是$\varepsilon$的独立同分布的样本，因而此时随机变量$y_i$也服从**正态分布**，即：

${y _i} \sim N({\beta _0} + {\beta _1}{x _i},{\sigma ^2})$

此时$y _1,y_2,\cdots,y_n$也是**独立不同分布**的随机变量

## 参数估计

### 普通最小二乘估计

普通最小二乘估计（Ordinary Least Square Estimation，OLSE）考虑观测值$y_i$与其回归值$E(y _i) = {\beta _0} + {\beta _1}{x _i}$ 的离差越小越好，考虑$n$ 个离差值，定义**离差平方和**为

$Q({\beta _0},{\beta _1}) = \sum\limits_{i = 1}^n {{{\left[ {{y_i} - E({y_i})} \right]}^2}}  = \sum\limits_{i = 1}^n {{{\left( {{y_i} - {\beta _0} - {\beta _1}{x_i}} \right)}^2}} $

寻找参数${\beta _0},{\beta _1}$ 的估计值${\hat \beta _0},{\hat \beta _1}$，**使离差平方和达到最**小。，求出的${\hat \beta _0},{\hat \beta _1}$ 就是回归参数${\beta _0},{\beta _1}$ 的最小二乘估计。

定义残差${e _i} = y _i - {\hat y _i}$ ，则残差平方和$\sum\limits_{i = 1}^n{e^2} =  \sum\limits_{i = 1}^n {{{\left( {{y_i} - {\hat \beta _0} - {\hat \beta _1}{x_i}} \right)}^2}}$ 

离差平方和分别对${\beta _0},{\beta _1}$ 求偏导，并令偏导数为0，求解方程组可得**参数估计值**

$\left\{ \begin{array}{l}
{{\hat \beta }_0} = \bar y - {{\hat \beta }_1}\bar x\\
{{\hat \beta }_1} = \frac{{\sum\limits_{i = 1}^n {({x_i} - \bar x)({y_i} - \bar y)} }}{{\sum\limits_{i = 1}^n {{{({x_i} - \bar x)}^2}} }}
\end{array} \right.$

式中$\bar x=\frac{1}{n}\sum\limits_{i=1}^n{x_i}, \bar y=\frac{1}{n}\sum\limits_{i=1}^n{y_i}$ 

且可以知道残差的有用性质

$\left\{ \begin{array}{l}
\sum\limits_{i = 1}^n {e_i^2}  = 0\\
\sum\limits_{i = 1}^n {{x_i}{e_i}}  = 0
\end{array} \right.$ .即残差的平均值为0，残差以自变量$x$ 为权重的加权平均值为0。

可记

$L_{xx} = \sum\limits_{i = 1}^n {{{({x_i} - \bar x)}^2}} = \sum\limits_{i = 1}^n {{x_i}^2 - n(\bar x)^2}$ 

$L_{xy} = \sum\limits_{i = 1}^n {(x_i - \bar x)(y_i - \bar y)} = \sum\limits_{i = 1}^n { {x_i}{y_i} - n \bar x \bar y}$ 

### 最大似然法

最大似然估计（Maximum Likelihood Estimate，MLE）是利用总体的分布密度或概率分布的表达式及其样本所提供的信息求未知参数估计量的方法。

当总体$X$ 为连续型分布时，设其分布函数族为$\{ f(x,\theta ),\theta  \in \Theta \} $ ，设总体$X$ 的一个独立同分布的样本为${x_1},{x_2}, \cdots ,{x_n}$ ，其似然函数为：

$L\left( {\theta ;{x_1},{x_2}, \cdots ,{x_n}} \right) = \prod\limits_{i = 1}^n {f({x_i},\theta )} $ 

最大