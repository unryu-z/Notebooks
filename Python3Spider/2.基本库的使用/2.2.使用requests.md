# 使用requests

https://2.python-requests.org/zh_CN/latest/

## 0. 标准的链接格式

以http://www.baidu.com/index.html;user?id=5#comment为例，标准的链接格式：

```
scheme://netloc/path;parameters?query#fragment
```

- `scheme`：代表**协议**，即`://`前面的内容；此处为`http`
- `netloc`：代表**域名**，即第一个`/`前的；此处为`www.baidu.com`
- `path`：代表**访问路径**；此处为`/index.html`，注意包含了`/`
- `params`：代表**参数**，即分号`;`后面的；此处为`user`
- `query` ：代表**查询条件**，即问号`?`后面的，易班用作GET类型的URL；此处为`id=5`
- `fragment`：代表**锚点**，即警号`#`后面的；此处即`comment`

`urllib `方法其中确实有不方便的地方，比如处理网页验证和 Cookies 时，需要写 `Opener` 和 `Handler` 来处理。为了更加方便地实现这些操作，就有了更为强大的库 `requests`，它可以实现Cookies、登录验证、代理设置等操作都。

## 1. 基本用法

首先需要安装`requests`库

### 发送请求`requests.get()、post()、put()、delete()`

requests 中有多种方法来实现**多种请求类型**，各请求类型说明见**1.1.请求**，示例：

```python
r = requests.get('https://api.github.com/events')	# 不带参数的 GET请求
r = requests.get(url='http://dict.baidu.com/s', params={'wd': 'python'})  	# 带参数的get请求
r = requests.post('http://httpbin.org/post', data = {'key':'value'})		# POST请求
r = requests.put('http://httpbin.org/put')			# PUT请求
r = requests.delete('http://httpbin.org/delete')	# DELETE请求
r = requests.head('http://httpbin.org/get')			# HEAD请求
r = requests.options('http://httpbin.org/get')		# OPTIONS请求
```

urllib 库中的 **`urlopen()` 方法**是以 GET 方式请求网页，而 requests 中相应的方法就是 **`get()` 方法**，实例：

```
import requests

r = requests.get('https://www.baidu.com/')
print(r)				# 响应对象
print(type(r))			# 响应对象的类型
print(r.status_code)	# 响应的状态码
print(type(r.text))		# text响应体的类型为 str
print(r.text)			# text响应体的内容
print(r.json())			# json响应体的内容
print(type(r.json())	# json响应体的类型为 dict
print(r.cookies)		# cookies的类型
```

运行结果如下（有乱码）：

```python
<Response [200]>
<class 'requests.models.Response'>
200
<class 'str'>
<!DOCTYPE html>
<!--STATUS OK--><html> <head><meta http-equiv=content-type content=text/html;charset=utf-8><meta http-equiv=X-UA-Compatible content=IE=Edge><meta content=always name=referrer><link rel=stylesheet type=text/css href=https://ss1.bdstatic.com/5eN1bjq8AAUYm2zgoY3K/r/www/cache/bdorz/baidu.min.css><title>ç¾åº¦ä¸ä¸ï¼ä½ å°±ç¥é</title></head> <body link=#0000cc> <div id=wrapper> <div id=head> <div class=head_wrapper> <div class=s_form> <div class=s_form_wrapper> <div id=lg> <img hidefocus=true src=//www.baidu.com/img/bd_logo1.png width=270 height=129> </div> <form id=form name=f action=//www.baidu.com/s class=fm> <input type=hidden name=bdorz_come value=1> <input type=hidden name=ie value=utf-8> <input type=hidden name=f value=8> <input type=hidden name=rsv_bp value=1> <input type=hidden name=rsv_idx value=1> <input type=hidden name=tn value=baidu><span class="bg s_ipt_wr"><input id=kw name=wd class=s_ipt value maxlength=255 autocomplete=off autofocus=autofocus></span><span class="bg s_btn_wr"><input type=submit id=su value=ç¾åº¦ä¸ä¸ class="bg s_btn" autofocus></span> </form> </div> </div> <div id=u1> <a href=http://news.baidu.com name=tj_trnews class=mnav>æ°é»</a> <a href=https://www.hao123.com name=tj_trhao123 class=mnav>hao123</a> <a href=http://map.baidu.com name=tj_trmap class=mnav>å°å¾</a> <a href=http://v.baidu.com name=tj_trvideo class=mnav>è§é¢</a> <a href=http://tieba.baidu.com name=tj_trtieba class=mnav>è´´å§</a> <noscript> <a href=http://www.baidu.com/bdorz/login.gif?login&amp;tpl=mn&amp;u=http%3A%2F%2Fwww.baidu.com%2f%3fbdorz_come%3d1 name=tj_login class=lb>ç»å½</a> </noscript> <script>document.write('<a href="http://www.baidu.com/bdorz/login.gif?login&tpl=mn&u='+ encodeURIComponent(window.location.href+ (window.location.search === "" ? "?" : "&")+ "bdorz_come=1")+ '" name="tj_login" class="lb">ç»å½</a>');
                </script> <a href=//www.baidu.com/more/ name=tj_briicon class=bri style="display: block;">æ´å¤äº§å</a> </div> </div> </div> <div id=ftCon> <div id=ftConw> <p id=lh> <a href=http://home.baidu.com>å³äºç¾åº¦</a> <a href=http://ir.baidu.com>About Baidu</a> </p> <p id=cp>&copy;2017&nbsp;Baidu&nbsp;<a href=http://www.baidu.com/duty/>ä½¿ç¨ç¾åº¦åå¿è¯»</a>&nbsp; <a href=http://jianyi.baidu.com/ class=cp-feedback>æè§åé¦</a>&nbsp;äº¬ICPè¯030173å·&nbsp; <img src=//www.baidu.com/img/gs.gif> </p> </div> </div> </div> </body> </html>

<RequestsCookieJar[<Cookie BDORZ=27315 for .baidu.com/>]>
```

修改乱码：

```python
>>> r.encoding				# 查看编码
'ISO-8859-1'
>>> r.apparent_encoding
'utf-8'
>>> r.encoding = 'utf-8'	# 修改编码
>>> print(r.text)
<!DOCTYPE html>
<!--STATUS OK--><html> <head><meta http-equiv=content-type content=text/html;charset=utf-8><meta http-equiv=X-UA-Compatible content=IE=Edge><meta content=always name=referrer><link rel=stylesheet type=text/css href=https://ss1.bdstatic.com/5eN1bjq8AAUYm2zgoY3K/r/www/cache/bdorz/baidu.min.css><title>百度一下，你就知道</title></head> <body link=#0000cc> <div id=wrapper> <div id=head> <div class=head_wrapper> <div class=s_form> <div class=s_form_wrapper> <div id=lg> <img hidefocus=true src=//www.baidu.com/img/bd_logo1.png width=270 height=129> </div> <form id=form name=f action=//www.baidu.com/s class=fm> <input type=hidden name=bdorz_come value=1> <input type=hidden name=ie value=utf-8> <input type=hidden name=f value=8> <input type=hidden name=rsv_bp value=1> <input type=hidden name=rsv_idx value=1> <input type=hidden name=tn value=baidu><span class="bg s_ipt_wr"><input id=kw name=wd class=s_ipt value maxlength=255 autocomplete=off autofocus=autofocus></span><span class="bg s_btn_wr"><input type=submit id=su value=百度一下 class="bg s_btn" autofocus></span> </form> </div> </div> <div id=u1> <a href=http://news.baidu.com name=tj_trnews class=mnav>新闻</a> <a href=https://www.hao123.com name=tj_trhao123 class=mnav>hao123</a> <a href=http://map.baidu.com name=tj_trmap class=mnav>地图</a> <a href=http://v.baidu.com name=tj_trvideo class=mnav>视频</a> <a href=http://tieba.baidu.com name=tj_trtieba class=mnav>贴吧</a> <noscript> <a href=http://www.baidu.com/bdorz/login.gif?login&amp;tpl=mn&amp;u=http%3A%2F%2Fwww.baidu.com%2f%3fbdorz_come%3d1 name=tj_login class=lb>登录</a> </noscript> <script>document.write('<a href="http://www.baidu.com/bdorz/login.gif?login&tpl=mn&u='+ encodeURIComponent(window.location.href+ (window.location.search === "" ? "?" : "&")+ "bdorz_come=1")+ '" name="tj_login" class="lb">登录</a>');
                </script> <a href=//www.baidu.com/more/ name=tj_briicon class=bri style="display: block;">更多产品</a> </div> </div> </div> <div id=ftCon> <div id=ftConw> <p id=lh> <a href=http://home.baidu.com>关于百度</a> <a href=http://ir.baidu.com>About Baidu</a> </p> <p id=cp>&copy;2017&nbsp;Baidu&nbsp;<a href=http://www.baidu.com/duty/>使用百度前必读</a>&nbsp; <a href=http://jianyi.baidu.com/ class=cp-feedback>意见反馈</a>&nbsp;京ICP证030173号&nbsp; <img src=//www.baidu.com/img/gs.gif> </p> </div> </div> </div> </body> </html>

```

编码查看方法："Network"-''Name"-"Headers"-"Response Headers"-"Content-Type: text/html;charset=utf-8"，但是有一些网页没有指定charset。

这里我们调用 `get()` 方法实现与 `urlopen()` 相同的操作，得到一个 `Response` 对象，然后分别输出了 **`Response` 的类型**为**`requests.models.Response`**、**status_code**状态码、**text**响应体的类型为`str`、内容以及 **Cookies**的类型是 `RequestsCookieJar`。

**实例：**

```
>>> import requests
>>> r = requests.get("https://www.bilibili.com")

>>> print(r.url)					# 请求的网址
https://www.bilibili.com/?rt=V%2FymTlOu4ow%2Fy4xxNWPUZ%2B%2BzdSDye%2BC55C%2Fga8wvi1k%3D

>>> print(r.status_code)			# 响应状态码
200

>>> print(r.request)				# 同 r.request
<PreparedRequest [GET]>
>>> print(r.request.headers)		# 请求头
{'User-Agent': 'python-requests/2.24.0', 
 'Accept-Encoding': 'gzip, deflate', 
 'Accept': '*/*', 
 'Connection': 'keep-alive', 
 'Cookie': 'main_confirmation=1Exdb3HTQJEUbcfe71lc1oQL1g26iquNu1cSXeZqGIU='}
 									# 此处有一个 Cookies

>>> print(r.text)					# 响应内容
<!DOCTYPE html><html lang="zh-CN"><head><me...

>>> print(r.headers)				# 响应头 无换行
{'Date': 'Mon, 15 Nov 2021 13:56:54 GMT', 
 'Content-Type': 'text/html; charset=utf-8', 
 'Transfer-Encoding': 'chunked', 
 'Connection': 'keep-alive', 
 'support': 'nantianmen', 
 'Set-Cookie': 'innersign=0; path=/; domain=.bilibili.com', 
 'cache-control': 'no-cache', 
 'gear': '1', 
 'Vary': 'Origin,Accept-Encoding', 
 'IDC': 'shjd', 
 'Content-Encoding': 'gzip', 
 'Expires': 'Mon, 15 Nov 2021 13:56:53 GMT', 
 'X-Cache-Webcdn': 'MISS from blzone01', 
 'X-Cache-Time': '0', 
 'X-Origin-Time': 'no-cache, must-revalidate, max-age=0, no-store', 
 'X-Save-Date': 'Mon, 15 Nov 2021 13:56:55 GMT'}

>>> print(r.cookies)
<RequestsCookieJar[<Cookie innersign=0 for .bilibili.com/>]>
>>> r.cookies						# Cookies
<RequestsCookieJar[Cookie(version=0, name='innersign', value='0', port=None, port_specified=False, domain='.bilibili.com', domain_specified=True, domain_initial_dot=True, path='/', path_specified=True, secure=False, expires=None, discard=True, comment=None, comment_url=None, rest={}, rfc2109=False)]>

>>> print(r.connection)				# 同 r.connection
<requests.adapters.HTTPAdapter object at 0x000001F999578508>

>>> print(r.elapsed)
0:00:00.696548
>>> r.elapsed
datetime.timedelta(microseconds=696548)
```



### 传递URL参数 `params={}`

你也许经常想为 URL 的**查询字符串(query string)**传递某种数据。如果你是手工构建 URL，那么数据会以**键/值**对的形式置于 URL 中，<u>跟在一个**问号**的后面</u>。例如， `httpbin.org/get?key=val`。 

Requests 允许你使用 **`params` 关键字参数**，以一个**字符串字典**来提供这些参数。举例来说，如果你想传递 `key1=value1` 和 `key2=value2` 到 `httpbin.org/get` ，示例：

```python
>>> payload = {'key1': 'value1', 'key2': 'value2'}  # 字符串字典 传递参数 值为None的键不会被添加到url中
>>> r = requests.get("http://httpbin.org/get", params=payload)  # 传递查询条件参数
>>> print(r.url)
http://httpbin.org/get?key2=value2&key1=value1
```

### 响应内容 `text`

若要读取服务器响应的内容，可以**访问`r.text`**，示例：

```python
>>> import requests
>>> r = requests.get('https://www.baidu.com/')	# 发起请求
>>> r.encoding				# 获取当前编码
'ISO-8859-1'
>>> r.encoding = 'utf-8'	# 修改当前编码为 utf-8
>>> r.text					# 以encoding的编码解析返回内容 字符串方式的响应体 会自动根据响应头部的字符编码进行解码
>>> r = requests.get('https://api.github.com/events')
>>> r.text
'[{"id":"15442735867","type":"WatchEvent","actor":{"id":15894433,...
```

注意**修改编码**后，解析的响应内容可以出现汉字，不会出现上面的乱码。

HTTP 和 XML 自身可以指定编码，此时，你应该使用 `r.content` 来找到编码，然后设置 `r.encoding` 为相应的编码。这样就能使用正确的编码解析 `r.text` 了。

### 二进制响应内容 `content`

若要以**字节**方式访问请求**响应体**，可以**访问`r.content`**，Requests 会自动为你解码 `gzip` 和 `deflate` 传输编码的响应数据，示例：

```python
>>> r.content				# 以字节形式（二进制）返回 会自动为你解码gzip和deflate传输编码的响应数据
b'<!DOCTYPE html>\r\n<!--STATUS OK--><html> <head><meta ...
```

以GitHub网站的图标为例：

```python
>>> import requests
>>> r = requests.get("https://github.com/favicon.ico")
>>> print(r.text)		# 输出str类型数据 图片原为二进制数据 出现乱码
...
>>> print(r.content)	# 得到bytes类型的数据
b'\x00\x00\x01\x00\x02\x00\x10\x10\x00\x00\x01\x00 \x00(\x05 ...
>>> with open('favicon.ico', 'wb') as f:	# 保存图片 为favicon.ico文件
...     f.write(r.content)
...     

```



### JSON响应内容 `json()`

Requests 中也有一个内置的 **JSON 解码器**，用来处理 JSON 数据，示例：

```python
>>> import requests
>>> r = requests.get('https://www.baidu.com/')
>>> r.json()				# json解码出错 
Traceback (most recent call last):
...
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)
>>> r = requests.get('https://api.github.com/events')
>>> r.json()				# 以json形式返回 前提是返回的内容确保是json格式的 不然解析出错会抛异常
[{'id': '15442474584', 'type': 'PushEvent', ...
>>> 
>>> import urllib.request
>>> response = urllib.request.urlopen("https://api.github.com/events")
>>> response.read()
b'[{"id":"15442693334","type":"PullRequestEvent","actor": ...
```

如果 **JSON 解码失败**， `r.json()` 就会抛出一个异常。例如，响应内容是 401 (Unauthorized)，尝试访问 `r.json()` 将会抛出 `ValueError: No JSON object could be decoded` 异常。

**注意**：成功调用 `r.json()` 并不意味着响应的成功。有的服务器会<u>在失败的响应中包含一个 JSON 对象</u>（比如 HTTP 500 的错误细节）。这种 JSON 对象会被解码返回。要检查请求是否成功，请使用 `r.raise_for_status()` 或者检查 `r.status_code` 是否和你的期望相同，示例：

```python
>>> r.raise_for_status()	# 请求成功 无输出
>>> r.status_code			# 请求成功时响应码200 失败请求(非200响应)抛出异常
200
```



### 原始响应内容 `raw`

若要获取来自服务器的原始响应体，可以**访问 `r.raw`**；并且你确保在**初始请求**中**设置了 `stream=True`**，示例：

```python
>>> r = requests.get('https://api.github.com/events', stream=True)  # 发起请求 且stream=True
>>> r.raw					# 返回原始响应体
<urllib3.response.HTTPResponse object at 0x000002A56CBDB5C8>
>>> r.raw.read(10)			# 使用 r.raw.read()
b'\x1f\x8b\x08\x00\x00\x00\x00\x00\x00\x03'
>>> import urllib.request
>>> response = urllib.request.urlopen("https://api.github.com/events")
>>> response
<http.client.HTTPResponse object at 0x000002A56CC05D88>
```

还可以以下面的模式将**文本流 保存到 文件**：

```python
with open(filename, 'wb') as fd:
    for chunk in r.iter_content(chunk_size):
        fd.write(chunk)
```

使用 `Response.iter_content` 将会处理大量你直接使用 `Response.raw` 不得不处理的。 当流下载时，上面是优先推荐的获取内容方式。 请注意，`chunk_size`可以自由调整为一个可能更适合你的用例的数字。

### 定制请求头 参数headers={}

为请求添加一个**HTTP头部**，需要传递一个**字典 `dict`** 给 **`headers` 参数**就可以了。

例如，在前一个示例中我们没有指定 content-type:

```python
>>> url = 'https://api.github.com/some/endpoint'
>>> Headers = {'user-agent': 'my-app/0.0.1'}

>>> r = requests.get(url, headers=Headers)
```

**注意**: 定制 header 的优先级低于某些特定的信息源，例如：

- 如果在 `.netrc` 中设置了用户认证信息，使用 headers= 设置的授权就不会生效。而如果设置了 `auth=` 参数，``.netrc`` 的设置就无效了。**(`auth=`>`.netrc`>`headers=`)**
- 如果被重定向到别的主机，授权 header 就会被**删除**。
- 代理授权 header 会**被 URL 中提供的代理身份覆盖**掉。
- 在我们能判断内容长度的情况下，header 的 Content-Length 会被改写。

更进一步讲，Requests 不会基于定制 header 的具体情况改变自己的行为。只不过在最后的请求中，所有的 header 信息都会被传递进去。

**注意**: 所有的 **header 值必须是 `string`、bytestring 或者 unicode**。尽管传递 unicode header 也是允许的，但不建议这样做。

### 复杂的POST请求

#### 字典 发送表单数据

要发送一些编码为**表单**形式的数据——非常像一个 HTML 表单，只需简单地传递一个**字典`dict`**给 **data 参数**。你的数据字典在发出请求时会**自动编码为表单**形式：

```python
>>> payload = {'key1': 'value1', 'key2': 'value2'}
>>> r = requests.post("http://httpbin.org/post", data=payload)
>>> print(r.text)
{
  "args": {}, 
  "data": "", 
  "files": {}, 
  "form": {
    "key1": "value1", 
    "key2": "value2"
  }, 
  "headers": {
    "Accept": "*/*", 
    "Accept-Encoding": "gzip, deflate", 
    "Content-Length": "23", 
    "Content-Type": "application/x-www-form-urlencoded", 
    "Host": "httpbin.org", 
    "User-Agent": "python-requests/2.24.0", 
    "X-Amzn-Trace-Id": "Root=1-617179f7-5e294b41267667d72ae4d0e7"
  }, 
  "json": null, 
  "origin": "113.14.175.192", 
  "url": "http://httpbin.org/post"
}
```

#### 元组 同一个key使用多个value

还可以为 `data` 参数传入一个**元组列表**。在表单中**同一个键key使用多个值value** 的时候，这种方式尤其有效：

```python
>>> payload = (('key1', 'value1'), ('key1', 'value2'))	# 注意此处使用小括号()创建元组 且没有冒号:
>>> r = requests.post('http://httpbin.org/post', data=payload)
>>> print(r.text)
{
  "args": {}, 
  "data": "", 
  "files": {}, 
  "form": {
    "key1": [
      "value1", 
      "value2"
    ]
  }, 
  "headers": {
    "Accept": "*/*", 
    "Accept-Encoding": "gzip, deflate", 
    "Content-Length": "23", 
    "Content-Type": "application/x-www-form-urlencoded", 
    "Host": "httpbin.org", 
    "User-Agent": "python-requests/2.24.0", 
    "X-Amzn-Trace-Id": "Root=1-605c9964-4a94eeb426080e6914ee2881"
  }, 
  "json": null, 
  "origin": "116.1.3.32", 
  "url": "http://httpbin.org/post"
}
```

#### 传递字符串string

很多时候你想要发送的数据并非编码为表单形式的。如果你传递一个 `string` 而不是一个 `dict`，那么数据会被直接发布出去。

示例，Github API v3 接受**编码为 JSON** 的 POST/PATCH 数据：

```python
>>> import json

>>> url = 'https://api.github.com/some/endpoint'
>>> payload = {'some': 'data'}							# 注意 冒号

>>> r = requests.post(url, data=json.dumps(payload))	# 注意 json.dunp
```

此处除了可以自行对 `dict` 进行编码，你还可以**使用 `json` 参数**直接传递，然后它就会被**自动编码为JSON**。这是 2.4.2 版的新加功能：

```python
>>> url = 'https://api.github.com/some/endpoint'
>>> payload = {'some': 'data'}

>>> r = requests.post(url, json=payload)
```

### POST一个多部分编码的文件（文件上传）

上传多部分编码(Multipart-Encoded)文件，示例：

```python
>>> import requests
>>> file = {'file': open('favicon.ico','rb')}		# 文件report.xls需要和脚本在同一目录下
>>> r = requests.post("http://httpbin.org/post", files=file)
>>> print(r.text)
{
  "args": {}, 
  "data": "", 
  "files": {
    "file": "data:application/octet-stream;base64,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"
  }, 
  "form": {}, 										# form字段是空的
  "headers": {
    "Accept": "*/*", 
    "Accept-Encoding": "gzip, deflate", 
    "Content-Length": "6665", 
    "Content-Type": "multipart/form-data; boundary=0efb22c3c2931b3ca61e796c2b674d99", 
    "Host": "httpbin.org", 
    "User-Agent": "python-requests/2.24.0", 
    "X-Amzn-Trace-Id": "Root=1-6186665f-3a3bd73437b7a63e45200c2e"
  }, 
  "json": null, 
  "origin": "113.14.196.31", 
  "url": "http://httpbin.org/post"
}
```

也可以**显式地设置*文件名*，*文件类型* 和*请求头***：

```python
>>> url = 'http://httpbin.org/post'
>>> files = {'file': ('report.xls', 					# 文件名
						open('report.xls', 'rb'), 		# 文件打开方式
						'application/vnd.ms-excel', 	# 文件类型
						{'Expires': '0'})				#
			}

>>> r = requests.post(url, files=files)
>>> r.text
{
  ...
  "files": {
    "file": "<censored...binary...data>"
  },
  ...
}
```

如果你想，你也可以发送作为文件来接收的字符串：

```python
>>> url = 'http://httpbin.org/post'
>>> files = {'file': ('report.csv', 'some,data,to,send\nanother,row,to,send\n')}

>>> r = requests.post(url, files=files)
>>> r.text
{
  ...
  "files": {
    "file": "some,data,to,send\\nanother,row,to,send\\n"
  },
  ...
}
```

如果你发送一个非常大的文件作为 `multipart/form-data` 请求，你可能希望将请求做成数据流。默认下 `requests` 不支持, 但有个第三方包 `requests-toolbelt` 是支持的。你可以阅读 [toolbelt 文档](https://toolbelt.rtfd.org/) 来了解使用方法。

在一个请求中发送多文件参考 [高级用法]如果你想，你也可以发送作为文件来接收的字符串：

```python
>>> url = 'http://httpbin.org/post'
>>> files = {'file': ('report.csv', 'some,data,to,send\nanother,row,to,send\n')}

>>> r = requests.post(url, files=files)
>>> r.text
{
  ...
  "files": {
    "file": "some,data,to,send\\nanother,row,to,send\\n"
  },
  ...
}
```

如果你发送一个非常大的文件作为 `multipart/form-data` 请求，你可能希望将请求做成数据流。默认下 `requests` 不支持, 但有个第三方包 `requests-toolbelt` 是支持的。你可以阅读 [toolbelt 文档](https://toolbelt.rtfd.org/) 来了解使用方法。

在一个请求中发送多文件参考 [高级用法](https://2.python-requests.org/zh_CN/latest/user/advanced.html#advanced) 一节。

警告

我们强烈建议你用二进制模式([binary mode](https://docs.python.org/2/tutorial/inputoutput.html#reading-and-writing-files))打开文件。这是因为 Requests 可能会试图为你提供 `Content-Length` header，在它这样做的时候，这个值会被设为文件的字节数（*bytes*）。如果用文本模式(text mode)打开文件，就可能会发生错误。 一节。

警告

我们强烈建议你用**二进制模式([binary mode](https://docs.python.org/2/tutorial/inputoutput.html#reading-and-writing-files))打开文件**。这是因为 Requests 可能会试图为你提供 `Content-Length` header，在它这样做的时候，这个值会被设为文件的字节数（*bytes*）。如果用文本模式(text mode)打开文件，就可能会发生错误。

### 状态响应码`status_code`

```python
>>> r = requests.get('http://httpbin.org/get')	# 发起请求
>>> print(type(r.status_code))					# 响应状态码的类型
<class 'int'>
>>> r.status_code								# 响应状态码
200
>>> r.status_code == requests.codes.ok			# 状态码查询对象
True
>>> r.raise_for_status()						# 没有异常
None

>>> bad_r = requests.get('http://httpbin.org/status/404')
>>> bad_r.status_code
404
>>> bad_r.raise_for_status()					# 通过 Response.raise_for_status() 来抛出异常
Traceback (most recent call last):
  File "requests/models.py", line 832, in raise_for_status
    raise http_error
requests.exceptions.HTTPError: 404 Client Error
```

resquest库自带状态码查询对象request.codes，下面是返回码和响应的查询条件：

```
# 信息性状态码
100: ('continue',),
101: ('switching_protocols',),
102: ('processing',),
103: ('checkpoint',),
122: ('uri_too_long', 'request_uri_too_long'),

# 成功状态码
200: ('ok', 'okay', 'all_ok', 'all_okay', 'all_good', '\\o/', '✓'),
201: ('created',),
202: ('accepted',),
203: ('non_authoritative_info', 'non_authoritative_information'),
204: ('no_content',),
205: ('reset_content', 'reset'),
206: ('partial_content', 'partial'),
207: ('multi_status', 'multiple_status', 'multi_stati', 'multiple_stati'),
208: ('already_reported',),
226: ('im_used',),

# 重定向状态码
300: ('multiple_choices',),
301: ('moved_permanently', 'moved', '\\o-'),
302: ('found',),
303: ('see_other', 'other'),
304: ('not_modified',),
305: ('use_proxy',),
306: ('switch_proxy',),
307: ('temporary_redirect', 'temporary_moved', 'temporary'),
308: ('permanent_redirect',
      'resume_incomplete', 'resume',), # These 2 to be removed in 3.0

# 客户端错误状态码
400: ('bad_request', 'bad'),
401: ('unauthorized',),
402: ('payment_required', 'payment'),
403: ('forbidden',),
404: ('not_found', '-o-'),
405: ('method_not_allowed', 'not_allowed'),
406: ('not_acceptable',),
407: ('proxy_authentication_required', 'proxy_auth', 'proxy_authentication'),
408: ('request_timeout', 'timeout'),
409: ('conflict',),
410: ('gone',),
411: ('length_required',),
412: ('precondition_failed', 'precondition'),
413: ('request_entity_too_large',),
414: ('request_uri_too_large',),
415: ('unsupported_media_type', 'unsupported_media', 'media_type'),
416: ('requested_range_not_satisfiable', 'requested_range', 'range_not_satisfiable'),
417: ('expectation_failed',),
418: ('im_a_teapot', 'teapot', 'i_am_a_teapot'),
421: ('misdirected_request',),
422: ('unprocessable_entity', 'unprocessable'),
423: ('locked',),
424: ('failed_dependency', 'dependency'),
425: ('unordered_collection', 'unordered'),
426: ('upgrade_required', 'upgrade'),
428: ('precondition_required', 'precondition'),
429: ('too_many_requests', 'too_many'),
431: ('header_fields_too_large', 'fields_too_large'),
444: ('no_response', 'none'),
449: ('retry_with', 'retry'),
450: ('blocked_by_windows_parental_controls', 'parental_controls'),
451: ('unavailable_for_legal_reasons', 'legal_reasons'),
499: ('client_closed_request',),

# 服务端错误状态码
500: ('internal_server_error', 'server_error', '/o\\', '✗'),
501: ('not_implemented',),
502: ('bad_gateway',),
503: ('service_unavailable', 'unavailable'),
504: ('gateway_timeout',),
505: ('http_version_not_supported', 'http_version'),
506: ('variant_also_negotiates',),
507: ('insufficient_storage',),
509: ('bandwidth_limit_exceeded', 'bandwidth'),
510: ('not_extended',),
511: ('network_authentication_required', 'network_auth', 'network_authentication')
```



### 响应头`headers`

```python
>>> r = requests.get('http://httpbin.org/get')
>>>> type(r.headers)							# 服务器响应头 的类型
<class 'requests.structures.CaseInsensitiveDict'>
>>> r.headers									# 服务器响应头 字典类型 以下输出内容实际未换行
{
	'Date': 'Thu, 25 Mar 2021 14:39:04 GMT', 
	'Content-Type': 'application/json', 
	'Content-Length': '303', 
	'Connection': 'keep-alive', 
	'Server': 'gunicorn/19.9.0', 
	'Access-Control-Allow-Origin': '*', 
	'Access-Control-Allow-Credentials': 'true'
}
>>> r.headers['Content-Type']					# HTTP头部对大小写不敏感
'application/json'
>>> r.headers['content-Type']
'application/json'
>>> r.requests.headers							# 返回发送到服务器的头信息
```

服务器可以多次接受同一 header，每次都使用不同的值。但 Requests 会将它们合并，这样它们就可以用一个映射来表示出来：接收者可以**合并多个相同名称的 header 栏位**，把它们合为一个 "field-name: field-value" 配对，将每个后续的栏位值依次追加到合并的栏位值中，用逗号隔开即可，这样做不会改变信息的语义。

### Cookies

```python
>>> url = 'http://example.com/some/cookie/setting/url'
>>> type(r.cookies)								# Cookies 的类型
<class 'requests.cookies.RequestsCookieJar'>
>>> r = requests.get(url)
>>> r.cookies
<RequestsCookieJar[]>
>>> r.cookies['example_cookie_name']			# 访问响应中的cookies
'example_cookie_value'

>>> url = 'http://httpbin.org/cookies'
>>> cookies = dict(cookies_are='working')		# dict()
>>> r = requests.get(url, cookies=cookies)		# 使用cookies参数 发送你的cookies到服务器
>>> r.text
'{"cookies": {"cookies_are": "working"}}'
```

Cookie 的返回对象为 [`RequestsCookieJar`](https://2.python-requests.org/zh_CN/latest/api.html#requests.cookies.RequestsCookieJar)，它的行为和字典类似，但接口更为完整，适合**跨域名、跨路径**使用。你还可以把 Cookie Jar 传到 Requests 中：

```python
>>> jar = requests.cookies.RequestsCookieJar()	# 创建一个CookiesJar对象

>>> jar.set('tasty_cookie', 'yum', domain='httpbin.org', path='/cookies')
...												# 设置第1个cookies
Cookie(version=0, name='tasty_cookie', value='yum', port=None, port_specified=False, domain='httpbin.org', domain_specified=True, domain_initial_dot=False, path='/cookies', path_specified=True, secure=False, expires=None, discard=True, comment=None, comment_url=None, rest={'HttpOnly': None}, rfc2109=False)

>>> jar.set('gross_cookie', 'blech', domain='httpbin.org', path='/elsewhere')
...												# 设置第2个cookies
Cookie(version=0, name='gross_cookie', value='blech', port=None, port_specified=False, domain='httpbin.org', domain_specified=True, domain_initial_dot=False, path='/elsewhere', path_specified=True, secure=False, expires=None, discard=True, comment=None, comment_url=None, rest={'HttpOnly': None}, rfc2109=False)

>>> jar											# 包含上面两个cookies
<RequestsCookieJar[Cookie(version=0, name='tasty_cookie', value='yum', port=None, port_specified=False, domain='httpbin.org', domain_specified=True, domain_initial_dot=False, path='/cookies', path_specified=True, secure=False, expires=None, discard=True, comment=None, comment_url=None, rest={'HttpOnly': None}, rfc2109=False), 
					Cookie(version=0, name='gross_cookie', value='blech', port=None, port_specified=False, domain='httpbin.org', domain_specified=True, domain_initial_dot=False, path='/elsewhere', path_specified=True, secure=False, expires=None, discard=True, comment=None, comment_url=None, rest={'HttpOnly': None}, rfc2109=False)]>

>>> url = 'http://httpbin.org/cookies'
>>> r = requests.get(url, cookies=jar)			# 将Cookiesjar传到requests中
>>> r.text										# 不使用 print() 
'{\n  "cookies": {\n    "tasty_cookie": "yum"\n  }\n}\n'
>>> print(r.text)								# 使用 print() 的区别
{
  "cookies": {
    "tasty_cookie": "yum"
  }
}
```

**实例：**

```python
>>> import requests
>>> r = requests.get("https://www.bilibili.com")
>>> print(r.request.headers)				# 请求头 无换行
{'User-Agent': 'python-requests/2.24.0', 
 'Accept-Encoding': 'gzip, deflate', 
 'Accept': '*/*', 
 'Connection': 'keep-alive', 
 'Cookie': 'main_confirmation=1Exdb3HTQJEUbcfe71lc1oQL1g26iquNu1cSXeZqGIU='}
 											# 替换这个 Cookies

# 替换请求头中的 Cookies
# 方法一
>>> headers = {'User-Agent': 'Chrome/53.0.2785.116 Safari/537.36',
              'Cookies': "b_ut=-1; i-wanna-go-back=1; _uuid=F0574B35-9A96-2075-AC80-959BF70804B206951infoc; buvid3=316D7615-CFA2-4AE3-8E47-14F327E49F09148821infoc; b_nut=1635943407; fingerprint=58ed101fc08e584d6d04ff0c37ce73d3; buvid_fp=316D7615-CFA2-4AE3-8E47-14F327E49F09148821infoc; buvid_fp_plain=316D7615-CFA2-4AE3-8E47-14F327E49F09148821infoc; SESSDATA=b54d1de6%2C1651505172%2Cbe241%2Ab1; bili_jct=90e7a294de3c996b64c815baf04fc8d8; DedeUserID=23117166; DedeUserID__ckMd5=7660b95c5a599761; sid=6mmf165o; video_page_version=v_old_home_4; blackside_state=1; rpdid=|(u)mY~mJuum0J'uYJYuu)|RY; CURRENT_BLACKGAP=1; CURRENT_QUALITY=0; bp_video_offset_23117166=589640993325298729; bp_t_offset_23117166=589907315657527119; CURRENT_FNVAL=80; PVID=1; innersign=0"
              }								# Cookies 使用双引号
>>> r = requests.get("https://www.bilibili.com", headers = headers)
>>> print(r.request.headers)				# 请求头 无换行		
{'User-Agent': 'Chrome/53.0.2785.116 Safari/537.36', 
 'Accept-Encoding': 'gzip, deflate', 
 'Accept': '*/*', 
 'Connection': 'keep-alive', 
 'Cookies': "b_ut=-1; i-wanna-go-back=1; _uuid=F0574B35-9A96-2075-AC80-959BF70804B206951infoc; buvid3=316D7615-CFA2-4AE3-8E47-14F327E49F09148821infoc; b_nut=1635943407; fingerprint=58ed101fc08e584d6d04ff0c37ce73d3; buvid_fp=316D7615-CFA2-4AE3-8E47-14F327E49F09148821infoc; buvid_fp_plain=316D7615-CFA2-4AE3-8E47-14F327E49F09148821infoc; SESSDATA=b54d1de6%2C1651505172%2Cbe241%2Ab1; bili_jct=90e7a294de3c996b64c815baf04fc8d8; DedeUserID=23117166; DedeUserID__ckMd5=7660b95c5a599761; sid=6mmf165o; video_page_version=v_old_home_4; blackside_state=1; rpdid=|(u)mY~mJuum0J'uYJYuu)|RY; CURRENT_BLACKGAP=1; CURRENT_QUALITY=0; bp_video_offset_23117166=589640993325298729; bp_t_offset_23117166=589907315657527119; CURRENT_FNVAL=80; PVID=1; innersign=0"}
											# 可以发现请求头中的 Cookies 和上面不同

# 方法二
>>> Cookies = "b_ut=-1; i-wanna-go-back=1; _uuid=F0574B35-9A96-2075-AC80-959BF70804B206951infoc; buvid3=316D7615-CFA2-4AE3-8E47-14F327E49F09148821infoc; b_nut=1635943407; fingerprint=58ed101fc08e584d6d04ff0c37ce73d3; buvid_fp=316D7615-CFA2-4AE3-8E47-14F327E49F09148821infoc; buvid_fp_plain=316D7615-CFA2-4AE3-8E47-14F327E49F09148821infoc; SESSDATA=b54d1de6%2C1651505172%2Cbe241%2Ab1; bili_jct=90e7a294de3c996b64c815baf04fc8d8; DedeUserID=23117166; DedeUserID__ckMd5=7660b95c5a599761; sid=6mmf165o; video_page_version=v_old_home_4; blackside_state=1; rpdid=|(u)mY~mJuum0J'uYJYuu)|RY; CURRENT_BLACKGAP=1; CURRENT_QUALITY=0; bp_video_offset_23117166=589640993325298729; bp_t_offset_23117166=589907315657527119; CURRENT_FNVAL=80; PVID=1; innersign=0"
>>> jar = requests.cookies.RequestsCookieJar()	
											# 创建一个CookiesJar对象

>>> for cookie in Cookies.split(';'):		# 按英文分号 ';' 拆分字符串 Cookies
...     key, value = cookie.split('=', 1)	# 按英文等号 '=' 拆分字符串 Cookies
...     jar.set(key, value)					# 设置 Cookies
...     
>>> headers = {'User-Agent': 'Chrome/53.0.2785.116 Safari/537.36'}
>>> r = requests.get("https://www.bilibili.com", cookies = jar, headers = headers)
>>> print(r.request.headers)
{'User-Agent': 'Chrome/53.0.2785.116 Safari/537.36', 
 'Accept-Encoding': 'gzip, deflate', 
 'Accept': '*/*', 
 'Connection': 'keep-alive', 
 'Cookie': " CURRENT_BLACKGAP=1;  CURRENT_FNVAL=80;  CURRENT_QUALITY=0;  DedeUserID=23117166;  DedeUserID__ckMd5=7660b95c5a599761;  PVID=1;  SESSDATA=b54d1de6%2C1651505172%2Cbe241%2Ab1;  _uuid=F0574B35-9A96-2075-AC80-959BF70804B206951infoc;  b_nut=1635943407;  bili_jct=90e7a294de3c996b64c815baf04fc8d8;  blackside_state=1;  bp_t_offset_23117166=589907315657527119;  bp_video_offset_23117166=589640993325298729;  buvid3=316D7615-CFA2-4AE3-8E47-14F327E49F09148821infoc;  buvid_fp=316D7615-CFA2-4AE3-8E47-14F327E49F09148821infoc;  buvid_fp_plain=316D7615-CFA2-4AE3-8E47-14F327E49F09148821infoc;  fingerprint=58ed101fc08e584d6d04ff0c37ce73d3;  i-wanna-go-back=1;  innersign=0;  rpdid=|(u)mY~mJuum0J'uYJYuu)|RY;  sid=6mmf165o;  video_page_version=v_old_home_4; b_ut=-1"}
											# Cookies 的顺序和方法一的不同
```



### 重定向和请求历史`history`

默认情况下，除了 HEAD，Requests 会**自动处理所有重定向**。可以使用**响应对象**的 **`history` 方法**来追踪重定向。

[`Response.history`](https://2.python-requests.org/zh_CN/latest/api.html#requests.Response.history) 是一个 [`Response`](https://2.python-requests.org/zh_CN/latest/api.html#requests.Response) 对象的**列表**，为了完成请求而创建了这些对象。这个对象列表按照从最老到最近的请求进行排序。

例如，Github 将所有的 HTTP 请求重定向到 HTTPS：

```python
>>> r = requests.get('http://github.com')

>>> r.url
'https://github.com/'

>>> r.status_code		# 响应状态码
200

>>> r.history			# 追踪重定向
[<Response [301]>]
```

如果你使用的是GET、OPTIONS、POST、PUT、PATCH 或者 DELETE，那么你可以通过 **`allow_redirects`** 参数**禁用重定向处理**：

```python
>>> r = requests.get('http://github.com', allow_redirects=False)	# 禁用重定向
>>> r.status_code		# 此处响应状态码发生变化
301
>>> r.history			# 可以看到重定向被禁止了
[]
```

如果你使用了 HEAD，你也可以启用重定向：

```
>>> r = requests.head('http://github.com', allow_redirects=True)
>>> r.url
'https://github.com/'
>>> r.history
[<Response [301]>]
```

### 超时

你可以告诉 requests 在经过以 **`timeout` 参数**设定的秒数时间之后**停止等待响应**。基本上所有的生产代码都应该使用这一参数。如果不使用，你的程序可能会永远失去响应：

```python
>>> requests.get('http://github.com', timeout=0.001)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
requests.exceptions.Timeout: HTTPConnectionPool(host='github.com', port=80): Request timed out. (timeout=0.001)
>>>> requests.get('http://www.bing.com', timeout=1)
<Response [200]>
```

**注意**: `timeout` 仅对连接过程有效，与响应体的下载无关。 `timeout` 并不是整个下载响应的时间限制，而是如果服务器在 `timeout` 秒内没有应答，将会引发一个异常（更精确地说，是在 `timeout` 秒内没有从基础套接字上接收到任何字节的数据时）If no timeout is specified explicitly, requests do not time out.

### 错误与异常

遇到网络问题（如：DNS 查询失败、拒绝连接等）时，Requests 会抛出一个 **`ConnectionError` 异常**。

如果 HTTP 请求返回了不成功的状态码， [`Response.raise_for_status()`](https://2.python-requests.org/zh_CN/latest/api.html#requests.Response.raise_for_status) 会抛出一个 **`HTTPError` 异常**。

若请求超时，则抛出一个 **`Timeout` 异常**。

若请求超过了设定的最大重定向次数，则会抛出一个 **`TooManyRedirects` 异常**。

所有Requests显式抛出的异常都继承自 `requests.exceptions.RequestException` 。

## 2.高级用法

### 会话对象Session

会话对象让你能够**跨请求保持某些参数**。它也会在同一个 **Session 实例**发出的所有请求之间保持 cookie， 期间使用 `urllib3` 的 [connection pooling](http://urllib3.readthedocs.io/en/latest/reference/index.html#module-urllib3.connectionpool) 功能。所以如果你向同一主机发送多个请求，底层的 TCP 连接将会被重用，从而带来显著的性能提升。 (参见 [HTTP persistent connection](https://en.wikipedia.org/wiki/HTTP_persistent_connection)).

会话对象**具有主要的 Requests API 的所有方法**。

我们来跨请求**保持 cookie**:

```python
>>> requests.get('http://httpbin.org/cookies/set/sessioncookie/123456789')
<Response [200]>
>>> r = requests.get("http://httpbin.org/cookies")
>>> print(r.text)														# 获得的cookie为空
{
  "cookies": {}
}

>>> s = requests.Session()												# 新建Session对象
>>> s.get('http://httpbin.org/cookies/set/sessioncookie/123456789')		# 设置cookie 名称为sessioncookie 内容为123456789
<Response [200]>
>>> r = s.get("http://httpbin.org/cookies")								# 获得当前cookie
>>> print(r.text)														# 保持上面设置的cookie
{
  "cookies": {
    "sessioncookie": "123456789"
  }
}
```

会话也可用来为请求方法 **提供缺省数据**。这是通过为会话对象的属性提供数据来实现的：

```python
>>> s = requests.Session()
>>> s.auth = ('user', 'pass')

>>> s.headers.update({'x-test': 'true'})		# 利用requests.Session,header.updata()设置会话的参数

>>> print(s.text)								# Session对象 没有text方法
Traceback (most recent call last):
  File "<input>", line 1, in <module>
AttributeError: 'Session' object has no attribute 'text'
    
>>> r= s.get('http://httpbin.org/headers', headers={'x-test2': 'true'})	
												# 同时发送'x-test'和'x-test2' 
>>> print(r.text)								# 'x-test'和'x-test2'合并了
{
  "headers": {
    "Accept": "*/*", 
    "Accept-Encoding": "gzip, deflate", 
    "Host": "httpbin.org", 
    "User-Agent": "python-requests/2.24.0", 
    "X-Amzn-Trace-Id": "Root=1-61874de9-71cf503532e3260f588a46b2", 
    "X-Test": "true", 
    "X-Test2": "true"
  }
}
>>> l = s.get('http://httpbin.org/headers')		# 跨请求 上一个请求r的参数没有保存
>>> print(l.text)
{
  "headers": {
    "Accept": "*/*", 
    "Accept-Encoding": "gzip, deflate", 
    "Host": "httpbin.org", 
    "User-Agent": "python-requests/2.24.0", 
    "X-Amzn-Trace-Id": "Root=1-61875049-0ac5ab3b17aaa7842b6451c4", 
    "X-Test": "true"
  }
}
```

**任何传递给请求方法的 *字典* 都会与已设置会话层数据 合并**。<u>方法层的参数 覆盖 会话的参数</u>。

不过需要注意，就算使用了会话，<u>方法级别的参数也不会被跨请求保持</u>。下面的例子只会和第一个请求发送 cookie ，而非第二个：

```python
>>> s = requests.Session()
>>> r = s.get('http://httpbin.org/cookies', cookies={'from-my': 'browser'})	# get方法的参数cookie
>>> print(r.text)												# cookie
{
  "cookies": {
    "from-my": "browser"
  }
}
>>> r = s.get('http://httpbin.org/cookies')						# 又一个请求 参数cookie没有保持
>>> print(r.text)												# 参数cookie为空
{
  "cookies": {}
}
```

如果你要手动为会话添加 cookie，就使用 [Cookie utility 函数](https://2.python-requests.org/zh_CN/latest/api.html#api-cookies) 来操纵 [`Session.cookies`](https://2.python-requests.org/zh_CN/latest/api.html#requests.Session.cookies)。

会话还可以用作**前后文管理器**：

```python
with requests.Session() as s:									# s = requests.Session()
    s.get('http://httpbin.org/cookies/set/sessioncookie/123456789')
```

这样就能确保 <u>`with` 区块退出后会话能被关闭</u>，即使发生了异常也一样。

<u>从字典参数中移除一个值</u>：

有时你会想省略字典参数中一些会话层的键。要做到这一点，你只需简单地在**方法层参数**中将那个键的值设置为 `None` ，那个键就会被自动**省略**掉。

包含在一个会话中的所有数据你都可以直接使用。学习更多细节请阅读 [会话 API 文档](https://2.python-requests.org/zh_CN/latest/api.html#sessionapi)。



### 请求Request与响应Response对象

任何时候进行了类似 **requests.get()** 的调用，你都在做两件主要的事情。其一，你在**构建一个 Request 对象**， 该对象将被发送到某个服务器请求或查询一些资源。其二，一旦 `requests` 得到一个从服务器返回的响应就会**产生一个 `Response` 对象**。该<u>响应对象包含服务器返回的所有信息，也包含你原来创建的 `Request` 对象</u>。如下是一个简单的请求，从 Wikipedia 的服务器得到一些非常重要的信息：

```python
>>> r = requests.get('http://www.bilibili.com')
```

如果想访问服务器返回给我们的**响应头部信息**，可以这样做：

```python
>>> r.headers													# 响应头
{'Date': 'Sun, 07 Nov 2021 12:20:56 GMT', 
	'Content-Type': 'text/html; charset=utf-8', 
	'Transfer-Encoding': 'chunked', 
	'Connection': 'keep-alive', 
	'support': 'nantianmen', 
	'Set-Cookie': 'innersign=0; path=/; domain=.bilibili.com', 
	'cache-control': 'no-cache', 
	'gear': '1', 
	'Vary': 'Origin,Accept-Encoding', 
	'Content-Encoding': 'gzip', 
	'Expires': 'Sun, 07 Nov 2021 12:20:55 GMT', 
	'X-Cache-Webcdn': 'MISS from blzone05', 
	'X-Cache-Time': '0', 
	'X-Origin-Time': 'no-cache, must-revalidate, max-age=0, no-store', 
	'X-Save-Date': 'Sun, 07 Nov 2021 12:20:56 GMT'}
```

然而，如果想得到**<u>发送到服务器的</u> 请求的 头部**，我们可以简单地访问该请求，然后是该请求的头部：

```python
>>> r.request.headers											# 发起的请求的头部
{'User-Agent': 'python-requests/2.24.0', 
	'Accept-Encoding': 'gzip, deflate', 
	'Accept': '*/*', 
	'Connection': 'keep-alive', 
	'Cookie': 'main_confirmation=x4m6iybJgynk5Btf1hA...'}
```



### 准备的请求 （Prepared Request）

当你从 API 或者会话调用中收到一个 [`Response`](https://2.python-requests.org/zh_CN/latest/api.html#requests.Response) 响应对象时，`request` 属性其实是使用了 **`PreparedRequest`对象**。有时在发送请求之前，你需要对 body 或者 header （或者别的什么东西）做一些额外处理，下面演示了一个简单的做法：

```python
from requests import Request, Session

s = Session()
req = Request('GET', url,				# 构造 Request对象
    data=data,
    headers=header
)
prepped = req.prepare()					# Request.prepare()

# do something with prepped.body
# do something with prepped.headers

resp = s.send(prepped,
    stream=stream,
    verify=verify,
    proxies=proxies,
    cert=cert,
    timeout=timeout
)

print(resp.status_code)
```

实例：

```python

```

由于你没有对 `Request` 对象做什么特殊事情，你立即准备和修改了 `PreparedRequest` 对象，然后把它和别的参数一起发送到 `requests.*` 或者 `Session.*`。

然而，上述代码会失去 Requests [`Session`](https://2.python-requests.org/zh_CN/latest/api.html#requests.Session) 对象的一些优势， 尤其 [`Session`](https://2.python-requests.org/zh_CN/latest/api.html#requests.Session) 级别的状态，例如 cookie 就不会被应用到你的请求上去。

要获取一个**带有状态的 [`PreparedRequest`](https://2.python-requests.org/zh_CN/latest/api.html#requests.PreparedRequest)**， 请用 [`Session.prepare_request()`](https://2.python-requests.org/zh_CN/latest/api.html#requests.Session.prepare_request) 取代 [`Request.prepare()`](https://2.python-requests.org/zh_CN/latest/api.html#requests.Request.prepare) 的调用，如下所示：

```python
>>> from requests import Request, Session
>>> url = 'http://httpbin.org/post'			# 使用网址'http://httpbin.org'时 无法请求

>>> data = {'name': 'germey'}
>>> headers = {'User-Agent': 'Chrome/53.0.2785.116 Safari/537.36'}

>>> s = Session()							# 构造Session对象 即 requests.Session()

>>> req = Request('POST', url, data=data, headers=headers)		# 构造 Request对象
>>> type(req)
<class 'requests.models.Request'>

>>> prepped = s.prepare_request(req)		# 使用 Session.prepare_request(Request) 方法
											# 将 Request对象 转化为 PreparedRequest对象
>>> type(prepped)
<class 'requests.models.PreparedRequest'>

>>> r = s.send(prepped)						# 调用 Session.send() 方法 发送请求
>>> print(r.text)
{
  "args": {}, 
  "data": "", 
  "files": {}, 
  "form": {
    "name": "germey"
  }, 
  "headers": {
    "Accept": "*/*", 
    "Accept-Encoding": "gzip, deflate", 
    "Content-Length": "11", 
    "Content-Type": "application/x-www-form-urlencoded", 
    "Host": "httpbin.org", 
    "User-Agent": "Chrome/53.0.2785.116 Safari/537.36", 
    "X-Amzn-Trace-Id": "Root=1-61925eac-6516383025be5b523c12af03"
  }, 
  "json": null, 
  "origin": "125.73.53.34", 
  "url": "http://httpbin.org/post"
}
```



### SSL 证书验证 `verify`

Requests 可以为 HTTPS 请求验证 SSL 证书，就像 web 浏览器一样。SSL 验证**默认**是**开启**的，如果证书验证失败，Requests 会抛出 **SSLError**:

```
>>> requests.get('https://requestb.in')
requests.exceptions.SSLError: hostname 'requestb.in' doesn't match either of '*.herokuapp.com', 'herokuapp.com'
```

在该域名上我没有设置 SSL，所以失败了。但 Github 设置了 SSL:

```
>>> requests.get('https://github.com', verify=True)			# 参数 verify=True  验证SSL证书
<Response [200]>
```

你可以为 `verify` 传入 **CA_BUNDLE 文件**的<u>路径</u>，或者包含可信任 CA 证书文件的文件夹路径：

```
>>> requests.get('https://github.com', verify='/path/to/certfile')
```

或者将其**保持在会话中**：

```python
>>> s = requests.Session()
>>> s.verify = '/path/to/certfile'				# requests.Session.verify 参数
```

**注解**：

如果 `verify` 设为文件夹路径，文件夹必须通过 OpenSSL 提供的 c_rehash 工具处理。

你还可以通过 **`REQUESTS_CA_BUNDLE` 环境变量**定义**可信任 CA 列表**。

如果你将 `verify` 设置为 False，Requests 也能忽略对 SSL 证书的验证。

```
>>> requests.get('https://kennethreitz.org', verify=False)	# 参数 verify=False 忽略证书验证
<Response [200]>
```

默认情况下， `verify` 是设置为 True 的。选项 `verify` 仅应用于主机证书。

\# 对于私有证书，你也可以传递一个 CA_BUNDLE 文件的路径给 `verify`。你也可以设置 # `REQUEST_CA_BUNDLE` 环境变量。

### 客户端证书

你也可以指定一个本地证书用作客户端证书，可以是单个文件（包含密钥和证书）或一个包含两个文件路径的元组：

```
>>> requests.get('https://kennethreitz.org', cert=('/path/client.cert', '/path/client.key'))
<Response [200]>
```

或者保持在会话中：

```
s = requests.Session()
s.cert = '/path/client.cert'
```

如果你指定了一个错误路径或一个无效的证书:

```
>>> requests.get('https://kennethreitz.org', cert='/wrong_path/client.pem')
SSLError: [Errno 336265225] _ssl.c:347: error:140B0009:SSL routines:SSL_CTX_use_PrivateKey_file:PEM lib
```

警告

警告

本地证书的私有 key 必须是解密状态。目前，Requests 不支持使用加密的 key。



### CA 证书

Requests 默认附带了一套它信任的根证书，来自于 [Mozilla trust store](https://hg.mozilla.org/mozilla-central/raw-file/tip/security/nss/lib/ckfw/builtins/certdata.txt)。然而它们在每次 Requests 更新时才会更新。这意味着如果你固定使用某一版本的 Requests，你的证书有可能已经 太旧了。

从 Requests 2.4.0 版之后，如果系统中装了 [certifi](http://certifi.io/) 包，Requests 会试图使用它里边的 证书。这样用户就可以在不修改代码的情况下更新他们的可信任证书。

为了安全起见，我们建议你经常更新 certifi！



### 响应体内容工作流

默认情况下，当你进行网络请求后，响应体会立即被下载。你可以通过 `stream` 参数覆盖这个行为，推迟下载响应体直到访问 [`Response.content`](https://2.python-requests.org/zh_CN/latest/api.html#requests.Response.content) 属性：

```
tarball_url = 'https://github.com/kennethreitz/requests/tarball/master'
r = requests.get(tarball_url, stream=True)
```

此时仅有响应头被下载下来了，连接保持打开状态，因此允许我们根据条件获取内容：

```
if int(r.headers['content-length']) < TOO_LONG:
  content = r.content
  ...
```

你可以进一步使用 [`Response.iter_content`](https://2.python-requests.org/zh_CN/latest/api.html#requests.Response.iter_content) 和 [`Response.iter_lines`](https://2.python-requests.org/zh_CN/latest/api.html#requests.Response.iter_lines) 方法来控制工作流，或者以 [`Response.raw`](https://2.python-requests.org/zh_CN/latest/api.html#requests.Response.raw) 从底层 urllib3 的 `urllib3.HTTPResponse <urllib3.response.HTTPResponse` 读取未解码的响应体。

如果你在请求中把 `stream` 设为 `True`，Requests 无法将连接释放回连接池，除非你 消耗了所有的数据，或者调用了 [`Response.close`](https://2.python-requests.org/zh_CN/latest/api.html#requests.Response.close)。 这样会带来连接效率低下的问题。如果你发现你在使用 `stream=True` 的同时还在部分读取请求的 body（或者完全没有读取 body），那么你就应该考虑使用 with 语句发送请求，这样可以保证请求一定会被关闭：

```
with requests.get('http://httpbin.org/get', stream=True) as r:
    # 在此处理响应。
```



### 保持活动状态（持久连接）

好消息——归功于 urllib3，同一会话内的持久连接是完全自动处理的！同一会话内你发出的任何请求都会自动复用恰当的连接！

注意：只有所有的响应体数据被读取完毕连接才会被释放为连接池；所以确保将 `stream` 设置为 `False` 或读取 `Response` 对象的 `content` 属性。



### 流式上传

Requests支持流式上传，这允许你发送大的数据流或文件而无需先把它们读入内存。要使用流式上传，仅需为你的请求体提供一个类文件对象即可：

```
with open('massive-body') as f:
    requests.post('http://some.url/streamed', data=f)
```

警告

警告

我们强烈建议你用二进制模式（[binary mode](https://docs.python.org/2/tutorial/inputoutput.html#reading-and-writing-files)）打开文件。这是因为 requests 可能会为你提供 header 中的 `Content-Length`，在这种情况下该值会被设为文件的**字节数**。如果你用**文本模式**打开文件，就可能碰到错误。



### 块编码请求

对于出去和进来的请求，Requests 也支持分块传输编码。要发送一个块编码的请求，仅需为你的请求体提供一个生成器（或任意没有具体长度的迭代器）：

```
def gen():
    yield 'hi'
    yield 'there'

requests.post('http://some.url/chunked', data=gen())
```

对于分块的编码请求，我们最好使用 `Response.iter_content()` 对其数据进行迭代。在理想情况下，你的 request 会设置 `stream=True`，这样你就可以通过调用 `iter_content` 并将分块大小参数设为 `None`，从而进行分块的迭代。如果你要设置分块的最大体积，你可以把分块大小参数设为任意整数。



### POST 多个分块编码的文件

你可以在一个请求中发送多个文件。例如，假设你要上传多个图像文件到一个 HTML 表单，使用一个多文件 field 叫做 "images":

```
<input type="file" name="images" multiple="true" required="true"/>
```

要实现，只要把文件设到一个元组的列表中，其中元组结构为 `(form_field_name, file_info)`:

```
>>> url = 'http://httpbin.org/post'
>>> multiple_files = [
        ('images', ('foo.png', open('foo.png', 'rb'), 'image/png')),
        ('images', ('bar.png', open('bar.png', 'rb'), 'image/png'))]
>>> r = requests.post(url, files=multiple_files)
>>> r.text
{
  ...
  'files': {'images': 'data:image/png;base64,iVBORw ....'}
  'Content-Type': 'multipart/form-data; boundary=3131623adb2043caaeb5538cc7aa0b3a',
  ...
}
```

警告

警告

我们强烈建议你用二进制模式（[binary mode](https://docs.python.org/2/tutorial/inputoutput.html#reading-and-writing-files)）打开文件。这是因为 requests 可能会为你提供 header 中的 `Content-Length`，在这种情况下该值会被设为文件的**字节数**。如果你用**文本模式**打开文件，就可能碰到错误。



### 事件挂钩

Requests有一个钩子系统，你可以用来操控部分请求过程，或信号事件处理。

可用的钩子:

- `response`:

  从一个请求产生的响应

你可以通过传递一个 `{hook_name: callback_function}` 字典给 `hooks` 请求参数为每个请求分配一个钩子函数：

```
hooks=dict(response=print_url)
```

`callback_function` 会接受一个数据块作为它的第一个参数。

```
def print_url(r, *args, **kwargs):
    print(r.url)
```

若执行你的回调函数期间发生错误，系统会给出一个警告。

若回调函数返回一个值，默认以该值替换传进来的数据。若函数未返回任何东西，也没有什么其他的影响。

我们来在运行期间打印一些请求方法的参数：

```
>>> requests.get('http://httpbin.org', hooks=dict(response=print_url))
http://httpbin.org
<Response [200]>
```



### 自定义身份验证

Requests 允许你使用自己指定的身份验证机制。

任何传递给请求方法的 `auth` 参数的可调用对象，在请求发出之前都有机会修改请求。

自定义的身份验证机制是作为 `requests.auth.AuthBase` 的子类来实现的，也非常容易定义。Requests 在 `requests.auth` 中提供了两种常见的的身份验证方案： `HTTPBasicAuth` 和 `HTTPDigestAuth` 。

假设我们有一个web服务，仅在 `X-Pizza` 头被设置为一个密码值的情况下才会有响应。虽然这不太可能，但就以它为例好了。

```
from requests.auth import AuthBase

class PizzaAuth(AuthBase):
    """Attaches HTTP Pizza Authentication to the given Request object."""
    def __init__(self, username):
        # setup any auth-related data here
        self.username = username

    def __call__(self, r):
        # modify and return the request
        r.headers['X-Pizza'] = self.username
        return r
```

然后就可以使用我们的PizzaAuth来进行网络请求:

```
>>> requests.get('http://pizzabin.org/admin', auth=PizzaAuth('kenneth'))
<Response [200]>
```



### 流式请求

使用 [`Response.iter_lines()`](https://2.python-requests.org/zh_CN/latest/api.html#requests.Response.iter_lines) 你可以很方便地对流式 API （例如 [Twitter 的流式 API](https://dev.twittercom/docs/streaming-api) ） 进行迭代。简单地设置 `stream` 为 `True` 便可以使用 [`iter_lines`](https://2.python-requests.org/zh_CN/latest/api.html#requests.Response.iter_lines) 对相应进行迭代：

```
import json
import requests

r = requests.get('http://httpbin.org/stream/20', stream=True)

for line in r.iter_lines():

    # filter out keep-alive new lines
    if line:
        decoded_line = line.decode('utf-8')
        print(json.loads(decoded_line))
```

当使用 decode_unicode=True 在 [`Response.iter_lines()`](https://2.python-requests.org/zh_CN/latest/api.html#requests.Response.iter_lines) 或 [`Response.iter_content()`](https://2.python-requests.org/zh_CN/latest/api.html#requests.Response.iter_content) 中时，你需要提供一个回退编码方式，以防服务器没有提供默认回退编码，从而导致错误：

```
r = requests.get('http://httpbin.org/stream/20', stream=True)

if r.encoding is None:
    r.encoding = 'utf-8'

for line in r.iter_lines(decode_unicode=True):
    if line:
        print(json.loads(line))
```

警告

警告

[`iter_lines`](https://2.python-requests.org/zh_CN/latest/api.html#requests.Response.iter_lines) 不保证重进入时的安全性。多次调用该方法 会导致部分收到的数据丢失。如果你要在多处调用它，就应该使用生成的迭代器对象:

```
lines = r.iter_lines()
# 保存第一行以供后面使用，或者直接跳过

first_line = next(lines)

for line in lines:
    print(line)
```



### 代理

如果需要使用代理，你可以通过为任意请求方法提供 `proxies` 参数来配置单个请求:

```
import requests

proxies = {
  "http": "http://10.10.1.10:3128",
  "https": "http://10.10.1.10:1080",
}

requests.get("http://example.org", proxies=proxies)
```

你也可以通过环境变量 `HTTP_PROXY` 和 `HTTPS_PROXY` 来配置代理。

```
$ export HTTP_PROXY="http://10.10.1.10:3128"
$ export HTTPS_PROXY="http://10.10.1.10:1080"

$ python
>>> import requests
>>> requests.get("http://example.org")
```

若你的代理需要使用HTTP Basic Auth，可以使用 http://user:password@host/ 语法：

```
proxies = {
    "http": "http://user:pass@10.10.1.10:3128/",
}
```

要为某个特定的连接方式或者主机设置代理，使用 scheme://hostname 作为 key， 它会针对指定的主机和连接方式进行匹配。

```
proxies = {'http://10.20.1.128': 'http://10.10.1.10:5323'}
```

注意，代理 URL 必须包含连接方式。

#### SOCKS

*2.10.0 新版功能.*

除了基本的 HTTP 代理，Request 还支持 SOCKS 协议的代理。这是一个可选功能，若要使用， 你需要安装第三方库。

你可以用 `pip` 获取依赖:

```
$ pip install requests[socks]
```

安装好依赖以后，使用 SOCKS 代理和使用 HTTP 代理一样简单：

```
proxies = {
    'http': 'socks5://user:pass@host:port',
    'https': 'socks5://user:pass@host:port'
}
```



### 合规性

Requests 符合所有相关的规范和 RFC，这样不会为用户造成不必要的困难。但这种对规范的考虑导致一些行为对于不熟悉相关规范的人来说看似有点奇怪。

#### 编码方式

当你收到一个响应时，Requests 会猜测响应的编码方式，用于在你调用 [`Response.text`](https://2.python-requests.org/zh_CN/latest/api.html#requests.Response.text) 方法时对响应进行解码。Requests 首先在 HTTP 头部检测是否存在指定的编码方式，如果不存在，则会使用 [charade](http://pypi.python.org/pypi/charade) 来尝试猜测编码方式。

只有当 HTTP 头部不存在明确指定的字符集，并且 `Content-Type` 头部字段包含 `text` 值之时， Requests 才不去猜测编码方式。在这种情况下， [RFC 2616](http://www.w3.org/Protocols/rfc2616/rfc2616-sec3.html#sec3.7.1) 指定默认字符集必须是 `ISO-8859-1` 。Requests 遵从这一规范。如果你需要一种不同的编码方式，你可以手动设置 [`Response.encoding`](https://2.python-requests.org/zh_CN/latest/api.html#requests.Response.encoding) 属性，或使用原始的 [`Response.content`](https://2.python-requests.org/zh_CN/latest/api.html#requests.Response.content)。



### HTTP动词

Requests 提供了几乎所有HTTP动词的功能：GET、OPTIONS、HEAD、POST、PUT、PATCH、DELETE。以下内容为使用 Requests 中的这些动词以及 Github API 提供了详细示例。

我将从最常使用的动词 GET 开始。HTTP GET 是一个幂等方法，从给定的 URL 返回一个资源。因而，当你试图从一个 web 位置获取数据之时，你应该使用这个动词。一个使用示例是尝试从 Github 上获取关于一个特定 commit 的信息。假设我们想获取 Requests 的 commit `a050faf` 的信息。我们可以这样去做：

```
>>> import requests
>>> r = requests.get('https://api.github.com/repos/requests/requests/git/commits/a050faf084662f3a352dd1a941f2c7c9f886d4ad')
```

我们应该确认 GitHub 是否正确响应。如果正确响应，我们想弄清响应内容是什么类型的。像这样去做：

```
>>> if (r.status_code == requests.codes.ok):
...     print r.headers['content-type']
...
application/json; charset=utf-8
```

可见，GitHub 返回了 JSON 数据，非常好，这样就可以使用 `r.json` 方法把这个返回的数据解析成 Python 对象。

```
>>> commit_data = r.json()

>>> print commit_data.keys()
[u'committer', u'author', u'url', u'tree', u'sha', u'parents', u'message']

>>> print commit_data[u'committer']
{u'date': u'2012-05-10T11:10:50-07:00', u'email': u'me@kennethreitz.com', u'name': u'Kenneth Reitz'}

>>> print commit_data[u'message']
makin' history
```

到目前为止，一切都非常简单。嗯，我们来研究一下 GitHub 的 API。我们可以去看看文档，但如果使用 Requests 来研究也许会更有意思一点。我们可以借助 Requests 的 OPTIONS 动词来看看我们刚使用过的 url 支持哪些 HTTP 方法。

```
>>> verbs = requests.options(r.url)
>>> verbs.status_code
500
```

额，这是怎么回事？毫无帮助嘛！原来 GitHub，与许多 API 提供方一样，实际上并未实现 OPTIONS 方法。这是一个恼人的疏忽，但没关系，那我们可以使用枯燥的文档。然而，如果 GitHub 正确实现了 OPTIONS，那么服务器应该在响应头中返回允许用户使用的 HTTP 方法，例如：

```
>>> verbs = requests.options('http://a-good-website.com/api/cats')
>>> print verbs.headers['allow']
GET,HEAD,POST,OPTIONS
```

转而去查看文档，我们看到对于提交信息，另一个允许的方法是 POST，它会创建一个新的提交。由于我们正在使用 Requests 代码库，我们应尽可能避免对它发送笨拙的 POST。作为替代，我们来玩玩 GitHub 的 Issue 特性。

本篇文档是回应 [Issue #482](https://github.com/requests/requests/issues/482) 而添加的。鉴于该问题已经存在，我们就以它为例。先获取它。

```
>>> r = requests.get('https://api.github.com/requests/kennethreitz/requests/issues/482')
>>> r.status_code
200

>>> issue = json.loads(r.text)

>>> print(issue[u'title'])
Feature any http verb in docs

>>> print(issue[u'comments'])
3
```

Cool，有 3 个评论。我们来看一下最后一个评论。

```
>>> r = requests.get(r.url + u'/comments')
>>> r.status_code
200
>>> comments = r.json()
>>> print comments[0].keys()
[u'body', u'url', u'created_at', u'updated_at', u'user', u'id']
>>> print comments[2][u'body']
Probably in the "advanced" section
```

嗯，那看起来似乎是个愚蠢之处。我们发表个评论来告诉这个评论者他自己的愚蠢。那么，这个评论者是谁呢？

```
>>> print comments[2][u'user'][u'login']
kennethreitz
```

好，我们来告诉这个叫 Kenneth 的家伙，这个例子应该放在快速上手指南中。根据 GitHub API 文档，其方法是 POST 到该话题。我们来试试看。

```
>>> body = json.dumps({u"body": u"Sounds great! I'll get right on it!"})
>>> url = u"https://api.github.com/repos/requests/requests/issues/482/comments"

>>> r = requests.post(url=url, data=body)
>>> r.status_code
404
```

额，这有点古怪哈。可能我们需要验证身份。那就有点纠结了，对吧？不对。Requests 简化了多种身份验证形式的使用，包括非常常见的 Basic Auth。

```
>>> from requests.auth import HTTPBasicAuth
>>> auth = HTTPBasicAuth('fake@example.com', 'not_a_real_password')

>>> r = requests.post(url=url, data=body, auth=auth)
>>> r.status_code
201

>>> content = r.json()
>>> print(content[u'body'])
Sounds great! I'll get right on it.
```

太棒了！噢，不！我原本是想说等我一会，因为我得去喂我的猫。如果我能够编辑这条评论那就好了！幸运的是，GitHub 允许我们使用另一个 HTTP 动词 PATCH 来编辑评论。我们来试试。

```
>>> print(content[u"id"])
5804413

>>> body = json.dumps({u"body": u"Sounds great! I'll get right on it once I feed my cat."})
>>> url = u"https://api.github.com/repos/requests/requests/issues/comments/5804413"

>>> r = requests.patch(url=url, data=body, auth=auth)
>>> r.status_code
200
```

非常好。现在，我们来折磨一下这个叫 Kenneth 的家伙，我决定要让他急得团团转，也不告诉他是我在捣蛋。这意味着我想删除这条评论。GitHub 允许我们使用完全名副其实的 DELETE 方法来删除评论。我们来清除该评论。

```
>>> r = requests.delete(url=url, auth=auth)
>>> r.status_code
204
>>> r.headers['status']
'204 No Content'
```

很好。不见了。最后一件我想知道的事情是我已经使用了多少限额（ratelimit）。查查看，GitHub 在响应头部发送这个信息，因此不必下载整个网页，我将使用一个 HEAD 请求来获取响应头。

```
>>> r = requests.head(url=url, auth=auth)
>>> print r.headers
...
'x-ratelimit-remaining': '4995'
'x-ratelimit-limit': '5000'
...
```

很好。是时候写个 Python 程序以各种刺激的方式滥用 GitHub 的 API，还可以使用 4995 次呢。

### 定制动词

有时候你会碰到一些服务器，处于某些原因，它们允许或者要求用户使用上述 HTTP 动词之外的定制动词。比如说 WEBDAV 服务器会要求你使用 MKCOL 方法。别担心，Requests 一样可以搞定它们。你可以使用内建的 `.request` 方法，例如：

```
>>> r = requests.request('MKCOL', url, data=data)
>>> r.status_code
200 # Assuming your call was correct
```

这样你就可以使用服务器要求的任意方法动词了。



### 响应头链接字段

许多 HTTP API 都有响应头链接字段的特性，它们使得 API 能够更好地自我描述和自我显露。

GitHub 在 API 中为 [分页](http://developer.github.com/v3/#pagination) 使用这些特性，例如:

```
>>> url = 'https://api.github.com/users/kennethreitz/repos?page=1&per_page=10'
>>> r = requests.head(url=url)
>>> r.headers['link']
'<https://api.github.com/users/kennethreitz/repos?page=2&per_page=10>; rel="next", <https://api.github.com/users/kennethreitz/repos?page=6&per_page=10>; rel="last"'
```

Requests 会自动解析这些响应头链接字段，并使得它们非常易于使用:

```
>>> r.links["next"]
{'url': 'https://api.github.com/users/kennethreitz/repos?page=2&per_page=10', 'rel': 'next'}

>>> r.links["last"]
{'url': 'https://api.github.com/users/kennethreitz/repos?page=7&per_page=10', 'rel': 'last'}
```



### 传输适配器

从 v1.0.0 以后，Requests 的内部采用了模块化设计。部分原因是为了实现传输适配器（Transport Adapter），你可以看看关于它的[最早描述](http://www.kennethreitz.org/essays/the-future-of-python-http)。传输适配器提供了一个机制，让你可以为 HTTP 服务定义交互方法。尤其是它允许你应用服务前的配置。

Requests 自带了一个传输适配器，也就是 [`HTTPAdapter`](https://2.python-requests.org/zh_CN/latest/api.html#requests.adapters.HTTPAdapter)。 这个适配器使用了强大的 [urllib3](https://github.com/shazow/urllib3)，为 Requests 提供了默认的 HTTP 和 HTTPS 交互。每当 [`Session`](https://2.python-requests.org/zh_CN/latest/api.html#requests.Session) 被初始化，就会有适配器附着在 [`Session`](https://2.python-requests.org/zh_CN/latest/api.html#requests.Session) 上，其中一个供 HTTP 使用，另一个供 HTTPS 使用。

Request 允许用户创建和使用他们自己的传输适配器，实现他们需要的特殊功能。创建好以后，传输适配器可以被加载到一个会话对象上，附带着一个说明，告诉会话适配器应该应用在哪个 web 服务上。

```
>>> s = requests.Session()
>>> s.mount('http://www.github.com', MyAdapter())
```

这个 mount 调用会注册一个传输适配器的特定实例到一个前缀上面。加载以后，任何使用该会话的 HTTP 请求，只要其 URL 是以给定的前缀开头，该传输适配器就会被使用到。

传输适配器的众多实现细节不在本文档的覆盖范围内，不过你可以看看接下来这个简单的 SSL 用例。更多的用法，你也许该考虑为 [`BaseAdapter`](https://2.python-requests.org/zh_CN/latest/api.html#requests.adapters.BaseAdapter) 创建子类。

#### 示例: 指定的 SSL 版本

Requests 开发团队刻意指定了内部库（[urllib3](https://github.com/shazow/urllib3)）的默认 SSL 版本。一般情况下这样做没有问题，不过是不是你可能会需要连接到一个服务节点，而该节点使用了和默认不同的 SSL 版本。

你可以使用传输适配器解决这个问题，通过利用 HTTPAdapter 现有的大部分实现，再加上一个 *ssl_version* 参数并将它传递到 `urllib3` 中。我们会创建一个传输适配器，用来告诉 `urllib3` 让它使用 SSLv3：

```
import ssl

from requests.adapters import HTTPAdapter
from requests.packages.urllib3.poolmanager import PoolManager


class Ssl3HttpAdapter(HTTPAdapter):
    """"Transport adapter" that allows us to use SSLv3."""

    def init_poolmanager(self, connections, maxsize, block=False):
        self.poolmanager = PoolManager(num_pools=connections,
                                       maxsize=maxsize,
                                       block=block,
                                       ssl_version=ssl.PROTOCOL_SSLv3)
```



### 阻塞和非阻塞

使用默认的传输适配器，Requests 不提供任何形式的非阻塞 IO。 [`Response.content`](https://2.python-requests.org/zh_CN/latest/api.html#requests.Response.content) 属性会阻塞，直到整个响应下载完成。如果你需要更多精细控制，该库的数据流功能（见 [流式请求](https://2.python-requests.org/zh_CN/latest/user/advanced.html#streaming-requests)） 允许你每次接受少量的一部分响应，不过这些调用依然是阻塞式的。

如果你对于阻塞式 IO 有所顾虑，还有很多项目可以供你使用，它们结合了 Requests 和 Python 的某个异步框架。典型的优秀例子是 [grequests](https://github.com/kennethreitz/grequests) 和 [requests-futures](https://github.com/ross/requests-futures)。

### Header 排序

在某些特殊情况下你也许需要按照次序来提供 header，如果你向 `headers` 关键字参数传入一个 `OrderedDict`，就可以向提供一个带排序的 header。**然而**，Requests 使用的默认 header 的次序会被优先选择，这意味着如果你在 `headers` 关键字参数中覆盖了默认 header，和关键字参数中别的 header 相比，它们也许看上去会是次序错误的。

如果这个对你来说是个问题，那么用户应该考虑在 [`Session`](https://2.python-requests.org/zh_CN/latest/api.html#requests.Session) 对象上面设置默认 header，只要将 [`Session`](https://2.python-requests.org/zh_CN/latest/api.html#requests.Session.headers) 设为一个定制的 `OrderedDict` 即可。这样就会让它成为优选的次序。



### 超时（timeout）

为防止服务器不能及时响应，大部分发至外部服务器的请求都应该带着 timeout 参数。在默认情况下，除非显式指定了 timeout 值，requests 是不会自动进行超时处理的。如果没有 timeout，你的代码可能会挂起若干分钟甚至更长时间。

**连接**超时指的是在你的客户端实现到远端机器端口的连接时（对应的是`connect()`_），Request 会等待的秒数。一个很好的实践方法是把连接超时设为比 3 的倍数略大的一个数值，因为 [TCP 数据包重传窗口 (TCP packet retransmission window)](http://www.hjp.at/doc/rfc/rfc2988.txt) 的默认大小是 3。

一旦你的客户端连接到了服务器并且发送了 HTTP 请求，**读取**超时指的就是客户端等待服务器发送请求的时间。（特定地，它指的是客户端要等待服务器发送字节**之间**的时间。在 99.9% 的情况下这指的是服务器发送第一个字节之前的时间）。

如果你制订了一个单一的值作为 timeout，如下所示：

```
r = requests.get('https://github.com', timeout=5)
```

这一 timeout 值将会用作 `connect` 和 `read` 二者的 timeout。如果要分别制定，就传入一个元组：

```
r = requests.get('https://github.com', timeout=(3.05, 27))
```

如果远端服务器很慢，你可以让 Request 永远等待，传入一个 None 作为 timeout 值，然后就冲咖啡去吧。

```
r = requests.get('https://github.com', timeout=None)
```

## 3.身份认证

本篇文档讨论如何配合 Requests 使用多种身份认证方式。

许多 web 服务都需要身份认证，并且也有多种不同的认证类型。 以下，我们会从简单到复杂概述 Requests 中可用的几种身份认证形式。

### 基本身份认证

许多要求身份认证的web服务都接受 HTTP Basic Auth。这是最简单的一种身份认证，并且 Requests 对这种认证方式的支持是直接开箱即可用。

以 HTTP Basic Auth 发送请求非常简单：

```
>>> from requests.auth import HTTPBasicAuth
>>> requests.get('https://api.github.com/user', auth=HTTPBasicAuth('user', 'pass'))
<Response [200]>
```

事实上，HTTP Basic Auth 如此常见，Requests 就提供了一种简写的使用方式：

```
>>> requests.get('https://api.github.com/user', auth=('user', 'pass'))
<Response [200]>
```

像这样在一个元组中提供认证信息与前一个 `HTTPBasicAuth` 例子是完全相同的。

### netrc 认证

如果认证方法没有收到 `auth` 参数，Requests 将试图从用户的 netrc 文件中获取 URL 的 hostname 需要的认证身份。The netrc file overrides raw HTTP authentication headers set with headers=.

如果找到了 hostname 对应的身份，就会以 HTTP Basic Auth 的形式发送请求。

### 摘要式身份认证

另一种非常流行的 HTTP 身份认证形式是摘要式身份认证，Requests 对它的支持也是开箱即可用的：

```
>>> from requests.auth import HTTPDigestAuth
>>> url = 'http://httpbin.org/digest-auth/auth/user/pass'
>>> requests.get(url, auth=HTTPDigestAuth('user', 'pass'))
<Response [200]>
```

### OAuth 1 认证

Oauth 是一种常见的 Web API 认证方式。 `requests-oauthlib` 库可以让 Requests 用户简单地创建 OAuth 认证的请求：

- ::

  `>>> import requests >>> from requests_oauthlib import OAuth1 ``>>> url = 'https://api.twitter.com/1.1/account/verify_credentials.json' >>> auth = OAuth1('YOUR_APP_KEY', 'YOUR_APP_SECRET', ...               'USER_OAUTH_TOKEN', 'USER_OAUTH_TOKEN_SECRET') ``>>> requests.get(url, auth=auth) <Response [200]> `

关于 OAuth 工作流程的更多信息，请参见 [OAuth](http://oauth.net/) 官方网站。 关于 requests-oauthlib 的文档和用例，请参见 GitHub 的 [requests_oauthlib](https://github.com/requests/requests-oauthlib) 代码库。

### OAuth 2 与 OpenID 连接认证

`requests-oauthlib` 库还可以处理 OAuth 2，OAuth 2 是 OpenID 连接的基础机制。 请查看 [requests-oauthlib OAuth2 documentation](http://requests-oauthlib.readthedocs.io/en/latest/oauth2_workflow.html) 文档以了解 OAuth 2 的各种认证管理流程：

- [Web Application Flow](http://requests-oauthlib.readthedocs.io/en/latest/oauth2_workflow.html#web-application-flow)
- [Mobile Application Flow](http://requests-oauthlib.readthedocs.io/en/latest/oauth2_workflow.html#mobile-application-flow)
- [Legacy Application Flow](http://requests-oauthlib.readthedocs.io/en/latest/oauth2_workflow.html#legacy-application-flow)
- [Backend Application Flow](http://requests-oauthlib.readthedocs.io/en/latest/oauth2_workflow.html#backend-application-flow)

### 其他身份认证形式

Requests 的设计允许其他形式的身份认证用简易的方式插入其中。开源社区的成员时常为更复杂或不那么常用的身份认证形式编写认证处理插件。其中一些最优秀的已被收集在 [Requests organization](https://github.com/requests) 页面中，包括:

- [Kerberos](https://github.com/requests/requests-kerberos)
- [NTLM](https://github.com/requests/requests-ntlm)

如果你想使用其中任何一种身份认证形式，直接去它们的 GitHub 页面，依照说明进行。

### 新的身份认证形式

如果你找不到所需要的身份认证形式的一个良好实现，你也可以自己实现它。Requests 非常易于添加你自己的身份认证形式。

要想自己实现，就从 [`AuthBase`](https://2.python-requests.org/zh_CN/latest/api.html#requests.auth.AuthBase) 继承一个子类，并实现 `__call__()` 方法：

```
>>> import requests
>>> class MyAuth(requests.auth.AuthBase):
...     def __call__(self, r):
...         # Implement my authentication
...         return r
...
>>> url = 'http://httpbin.org/get'
>>> requests.get(url, auth=MyAuth())
<Response [200]>
```

当一个身份认证模块被附加到一个请求上，在设置 request 期间就会调用该模块。因此 `__call__` 方法必须完成使得身份认证生效的所有事情。一些身份认证形式会额外地添加钩子来提供进一步的功能。